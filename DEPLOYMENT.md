# üöÄ Render Deployment Checklist

## ‚úÖ Pre-Deployment Checklist

### 1. Files Required
- [x] `app.py` - Flask application
- [x] `requirements.txt` - Python dependencies
- [x] `Procfile` - Gunicorn configuration
- [x] `runtime.txt` - Python version
- [x] `animals10_model.keras` - Trained model
- [x] `templates/index.html` - Frontend
- [x] `static/style.css` - Styles
- [x] `static/script.js` - JavaScript
- [x] `.gitignore` - Git ignore rules
- [x] `README.md` - Documentation

### 2. Code Verification
- [x] Flask app runs locally without errors
- [x] Model loads successfully
- [x] All routes work (`/`, `/predict`, `/health`)
- [x] Static files are served correctly
- [x] Frontend UI is responsive and functional
- [x] Error handling is implemented

### 3. Configuration
- [x] PORT environment variable handled
- [x] Gunicorn configured with appropriate workers
- [x] Timeout set to 120 seconds (for model loading)
- [x] CORS enabled (flask-cors)
- [x] Logging configured

## üì¶ Model File Handling

### Option 1: Include Model in Git (Recommended if < 100MB)
```bash
# Check model size
ls -lh animals10_model.keras

# If less than 100MB, commit it
git add animals10_model.keras
git commit -m "Add trained model"
git push
```

### Option 2: Download Model at Build Time (If model > 100MB)
Add to `Procfile` or create `build.sh`:
```bash
# build.sh
#!/bin/bash
pip install gdown
gdown <GOOGLE_DRIVE_FILE_ID> -O animals10_model.keras
```

Update Procfile:
```
web: bash build.sh && gunicorn app:app
```

## üåê Render Setup Steps

### Step 1: Create New Web Service
1. Go to https://dashboard.render.com/
2. Click **"New +"** ‚Üí **"Web Service"**
3. Connect your GitHub repository

### Step 2: Configure Service
```
Name: animal-classifier
Environment: Python 3
Region: Choose closest to your users
Branch: main
Build Command: pip install -r requirements.txt
Start Command: gunicorn app:app --bind 0.0.0.0:$PORT --workers 2 --timeout 120
```

### Step 3: Advanced Settings
- **Instance Type**: Free (or Starter for better performance)
- **Environment Variables**:
  - `DEBUG`: `false`
  - `PORT`: (Auto-set by Render)
  - `PYTHONUNBUFFERED`: `1` (Optional, for better logging)

### Step 4: Deploy
Click **"Create Web Service"** and wait 5-10 minutes for:
1. Code pull from GitHub
2. Dependencies installation
3. Application startup

## üîç Post-Deployment Testing

### 1. Health Check
```bash
curl https://your-app-name.onrender.com/health
```
Expected response:
```json
{
  "status": "healthy",
  "model_loaded": true,
  "message": "Animal Classification API is running üöÄ"
}
```

### 2. Main Page
Visit: `https://your-app-name.onrender.com/`
- Should load the UI
- Should show upload area
- Should display supported animals

### 3. Test Prediction
1. Upload an animal image
2. Click "Predict Animal"
3. Verify prediction and confidence score

## üêõ Common Issues & Solutions

### Issue 1: "ModuleNotFoundError"
**Cause**: Missing dependency in requirements.txt
**Solution**:
```bash
pip freeze > requirements.txt
git add requirements.txt
git commit -m "Update dependencies"
git push
```

### Issue 2: "Model not loading"
**Cause**: Model file missing or wrong path
**Solution**:
- Verify `animals10_model.keras` is in root directory
- Check build logs for errors
- Ensure model is pushed to GitHub

### Issue 3: "Application failed to start"
**Cause**: Port binding or timeout issues
**Solution**:
- Ensure app uses `PORT` environment variable
- Increase timeout in Procfile if model loading is slow
```
web: gunicorn app:app --bind 0.0.0.0:$PORT --workers 2 --timeout 300
```

### Issue 4: "Static files not loading"
**Cause**: Incorrect Flask configuration
**Solution**:
- Use `{{ url_for('static', filename='...') }}` in templates
- Verify folder structure: `static/` and `templates/`

### Issue 5: "Cold start is very slow"
**Cause**: Free tier sleeps after 15 minutes of inactivity
**Solution**:
- Upgrade to Starter plan ($7/month)
- Use a health check service (UptimeRobot, etc.)
- Accept 30-60 second first-load delay

### Issue 6: "Memory issues"
**Cause**: Free tier has 512MB RAM limit
**Solution**:
- Reduce model size if possible
- Use lighter model architecture
- Upgrade to Starter plan (512MB+)

## üìä Monitoring

### Render Dashboard
- View logs: Click on your service ‚Üí "Logs" tab
- Monitor CPU/Memory: "Metrics" tab
- Check deploy history: "Events" tab

### Custom Logging
The app includes logging:
```python
logger.info("Model loaded successfully")
logger.error("Prediction error")
```
View these in Render logs.

## üîê Security Best Practices

### For Production:
1. **Rate Limiting**: Add Flask-Limiter
```python
from flask_limiter import Limiter
limiter = Limiter(app, default_limits=["100 per hour"])
```

2. **File Upload Validation**:
- Check file size (max 10MB recommended)
- Validate file extensions
- Scan for malicious content

3. **HTTPS**: Render provides free SSL
4. **Environment Variables**: Never commit sensitive data
5. **CORS**: Restrict origins in production

## üöÄ Performance Optimization

### 1. Model Optimization
- Use TensorFlow Lite for smaller model
- Quantize model weights
- Use MobileNet or EfficientNet

### 2. Caching
- Cache static assets
- Use CDN for CSS/JS
- Cache model predictions (if applicable)

### 3. Async Processing
- Use background workers for heavy tasks
- Implement request queuing

## üìà Scaling

### Free Tier Limitations:
- 512MB RAM
- Sleeps after 15 min inactivity
- Limited CPU

### Upgrade Path:
1. **Starter ($7/mo)**: 512MB RAM, no sleep
2. **Standard ($25/mo)**: 2GB RAM, better CPU
3. **Pro ($85/mo)**: 4GB RAM, dedicated resources

## üîÑ Continuous Deployment

### Auto-Deploy on Git Push:
1. In Render dashboard, go to your service
2. Settings ‚Üí Build & Deploy
3. Enable "Auto-Deploy": Yes
4. Select branch: `main`

Now every push to `main` automatically deploys!

## üìû Support

### Render Documentation
- https://render.com/docs
- https://render.com/docs/deploy-flask

### Flask Documentation
- https://flask.palletsprojects.com/

### TensorFlow Serving
- https://www.tensorflow.org/tfx/guide/serving

## ‚úÖ Final Verification

Before going live, verify:
- [ ] App loads at Render URL
- [ ] Can upload images
- [ ] Predictions work correctly
- [ ] UI looks good on mobile
- [ ] Error messages are user-friendly
- [ ] Logs show no errors
- [ ] Health endpoint responds
- [ ] Performance is acceptable

## üéâ You're Live!

Your Animal Classifier AI is now deployed!

Share your app:
```
https://your-app-name.onrender.com
```

Next steps:
1. Add analytics (Google Analytics, etc.)
2. Gather user feedback
3. Improve model accuracy
4. Add more features
5. Monitor performance

---

**Happy Deploying! üöÄ**
